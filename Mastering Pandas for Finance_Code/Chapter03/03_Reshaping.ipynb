{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping, Reorganizing and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and NumPy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# date and time functions\n",
    "import datetime\n",
    "\n",
    "# bring in matplotlib and draw inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set some Pandas options\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading historical stock data from the web or from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.io.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7304698d1723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# for the DataReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mweb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# start end end dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2012\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.io.data'"
     ]
    }
   ],
   "source": [
    "# for the DataReader\n",
    "import pandas.io.data as web\n",
    "\n",
    "# start end end dates\n",
    "start = datetime.datetime(2012, 1, 1)\n",
    "end = datetime.datetime(2012, 12, 30)\n",
    "\n",
    "# load the data\n",
    "msft = web.DataReader(\"MSFT\", 'yahoo', start, end)\n",
    "aapl = web.DataReader(\"AAPL\", 'yahoo', start, end)\n",
    "\n",
    "# these save the data to file - optional for the examples\n",
    "#msft.to_csv(\"msft.csv\")\n",
    "#aapl.to_csv(\"aapl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Microsoft and Apple data from file\n",
    "msft = pd.read_csv(\"msft.csv\", index_col=0, parse_dates=True)\n",
    "aapl = pd.read_csv(\"aapl.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing the data for the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open   High    Low  Close    Volume  Adj Close\n",
       "Date                                                       \n",
       "2012-01-03  26.55  26.96  26.39  26.77  64731500     24.422\n",
       "2012-01-04  26.82  27.47  26.78  27.40  80516100     24.997\n",
       "2012-01-05  27.38  27.73  27.29  27.68  56081400     25.252"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              Open    High     Low   Close    Volume  Adj Close\n",
       "Date                                                           \n",
       "2012-01-03  409.40  412.50  409.00  411.23  75555200     55.414\n",
       "2012-01-04  410.00  414.68  409.28  413.44  65005500     55.711\n",
       "2012-01-05  414.95  418.55  412.67  418.03  67817400     56.330"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aapl.index.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganizing and reshaping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating data in Multiple DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get MSFT adjusted close data for Jan and Feb 2012\n",
    "msftA01 = msft['2012-01'][['Adj Close']]\n",
    "msftA02 = msft['2012-02'][['Adj Close']]\n",
    "msftA01[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-02-01     27.268\n",
       "2012-02-02     27.323\n",
       "2012-02-03     27.587"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msftA02[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252\n",
       "2012-02-01     27.268\n",
       "2012-02-02     27.323\n",
       "2012-02-03     27.587"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the first three rows of each of msftA01 and msftA02\n",
    "pd.concat([msftA01.head(3), msftA02.head(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252\n",
       "2012-01-03     55.414\n",
       "2012-01-04     55.711\n",
       "2012-01-05     56.330"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only the Jan 2012 AAPL values.  \n",
    "aaplA01 = aapl['2012-01'][['Adj Close']]\n",
    "# now concat the AAPL and MSFT Jan 2012 data\n",
    "# there will be duplicate index labels\n",
    "withDups = pd.concat([msftA01[:3], aaplA01[:3]])\n",
    "withDups\n",
    "\n",
    "# renc: !! two procudt (AAPL, MSFT) with the same days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-03     55.414"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the two records for data of 2012-01-03\n",
    "withDups.ix['2012-01-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 Adj Close\n",
       "     Date                 \n",
       "MSFT 2012-01-03     24.422\n",
       "     2012-01-04     24.997\n",
       "     2012-01-05     25.252\n",
       "AAPL 2012-01-03     55.414\n",
       "     2012-01-04     55.711\n",
       "     2012-01-05     56.330"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate concat with a specification of the \n",
    "# stock tickets being part of the index\n",
    "# this help disambiguate the duplicate dates using\n",
    "# a hierarchal index\n",
    "closes = pd.concat([msftA01[:3], aaplA01[:3]], \n",
    "                    keys=['MSFT', 'AAPL'])\n",
    "closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract just MSFT values using .ix\n",
    "closes.ix['MSFT'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closes.loc['MSFT', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closes.loc['MSFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close     Volume\n",
       "Date                            \n",
       "2012-01-03     24.422   64731500\n",
       "2012-01-04     24.997   80516100\n",
       "2012-01-05     25.252   56081400\n",
       "2012-01-06     25.644   99455500\n",
       "...               ...        ...\n",
       "2012-12-24     70.716   43938300\n",
       "2012-12-26     69.741   75609100\n",
       "2012-12-27     70.021  113780100\n",
       "2012-12-28     69.278   88569600\n",
       "\n",
       "[498 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate concatenation using two DataFrame's\n",
    "# that each have two columns.  pandas will align the\n",
    "# data in columns by the column names (labels)\n",
    "msftAV = msft[['Adj Close', 'Volume']]\n",
    "aaplAV = aapl[['Adj Close', 'Volume']]\n",
    "pd.concat([msftAV, aaplAV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            Adj Close     Volume\n",
       "Date                            \n",
       "2012-01-03     24.422  6.473e+07\n",
       "2012-01-04     24.997  8.052e+07\n",
       "2012-01-05     25.252  5.608e+07\n",
       "2012-01-06     25.644  9.946e+07\n",
       "...               ...        ...\n",
       "2012-12-24     70.716        NaN\n",
       "2012-12-26     69.741        NaN\n",
       "2012-12-27     70.021        NaN\n",
       "2012-12-28     69.278        NaN\n",
       "\n",
       "[498 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate concatenation with DataFrame objects\n",
    "# that do not have the same set of columns\n",
    "# this demonstrates pandas filling in NaN values\n",
    "aaplA = aapl[['Adj Close']]\n",
    "pd.concat([msftAV, aaplA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252\n",
       "2012-01-06     25.644\n",
       "...               ...\n",
       "2012-12-24     70.716\n",
       "2012-12-26     69.741\n",
       "2012-12-27     70.021\n",
       "2012-12-28     69.278\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform an inner join on the DataFrame's\n",
    "# since aaplA does not have a Volume column, pandas\n",
    "# will not include that column in the result\n",
    "pd.concat([msftAV, aaplA], join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close  Adj Close\n",
       "Date                            \n",
       "2012-01-03     24.422     55.414\n",
       "2012-01-04     24.997     55.711\n",
       "2012-01-05     25.252     56.330"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat along the rows, causing duplicate columns to\n",
    "# be created in the result\n",
    "msftA = msft[['Adj Close']]\n",
    "closes = pd.concat([msftA, aaplA], axis=1)\n",
    "closes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                MSFT                AAPL           \n",
       "           Adj Close    Volume Adj Close     Volume\n",
       "Date                                               \n",
       "2012-01-03    24.422  64731500    55.414  7.556e+07\n",
       "2012-01-04    24.997  80516100    55.711  6.501e+07\n",
       "2012-01-05    25.252  56081400    56.330  6.782e+07\n",
       "2012-01-06    25.644  99455500       NaN        NaN\n",
       "2012-01-09    25.307  59706800       NaN        NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat along rows using two DataFrame objects with\n",
    "# different number of rows. This demonstrates how\n",
    "# NaN values will be filled in those rows for AAPL\n",
    "# which only hase three rows as compared to 5 for MSFT\n",
    "pd.concat([msftAV[:5], aaplAV[:3]], axis=1,\n",
    "          keys=['MSFT', 'AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                MSFT      AAPL\n",
       "           Adj Close Adj Close\n",
       "Date                          \n",
       "2012-01-03    24.422    55.414\n",
       "2012-01-04    24.997    55.711\n",
       "2012-01-05    25.252    56.330"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inner join can also be used along this axis\n",
    "# this will not include rows with index labels that do\n",
    "# not exist in both DataFrame objects\n",
    "pd.concat([msftA[:5], aaplA[:3]], axis=1,\n",
    "          join='inner', keys=['MSFT', 'AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Adj Close\n",
       "0     24.422\n",
       "1     24.997\n",
       "2     25.252\n",
       "3     55.414\n",
       "4     55.711\n",
       "5     56.330"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore indexes and just concatenate the data and\n",
    "# have the result have a default integer index\n",
    "pd.concat([msftA[:3], aaplA[:3]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2012-01-03     24.422\n",
       "2012-01-04     24.997\n",
       "2012-01-05     25.252\n",
       "2012-01-06     25.644\n",
       "...               ...\n",
       "2012-12-24     25.385\n",
       "2012-12-26     25.197\n",
       "2012-12-27     25.291\n",
       "2012-12-28     24.906\n",
       "\n",
       "[249 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msftA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date  Adj Close\n",
       "0 2012-01-03     24.422\n",
       "1 2012-01-04     24.997\n",
       "2 2012-01-05     25.252"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will merge these two DataFrame objects, \n",
    "# so lets peek at the data to remind ourselves\n",
    "# of what they contain\n",
    "msftAR = msftA.reset_index()\n",
    "msftVR = msft[['Volume']].reset_index()\n",
    "msftAR[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date    Volume\n",
       "0 2012-01-03  64731500\n",
       "1 2012-01-04  80516100\n",
       "2 2012-01-05  56081400"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msftVR[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date  Adj Close    Volume\n",
       "0 2012-01-03     24.422  64731500\n",
       "1 2012-01-04     24.997  80516100\n",
       "2 2012-01-05     25.252  56081400\n",
       "3 2012-01-06     25.644  99455500\n",
       "4 2012-01-09     25.307  59706800"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two.  pandas finds the columns in common,\n",
    "# in this case Date, and merges on that column and adds\n",
    "# a column for all the other columns in both DataFrame's\n",
    "msftCVR = pd.merge(msftAR, msftVR)\n",
    "msftCVR[:5]\n",
    "\n",
    "# renc: i suspect that merge two df, these df have one common column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date  Adj Close\n",
       "0 2012-01-03     24.422\n",
       "1 2012-01-04     24.997\n",
       "2 2012-01-05     25.252\n",
       "3 2012-01-06     25.644\n",
       "4 2012-01-09     25.307"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will demonstrate join semantics using this DataFrame\n",
    "msftAR0_5 = msftAR[0:5]\n",
    "msftAR0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date    Volume\n",
       "2 2012-01-05  56081400\n",
       "3 2012-01-06  99455500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and also this one\n",
    "msftVR2_4 = msftVR[2:4]\n",
    "msftVR2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date  Adj Close    Volume\n",
       "0 2012-01-05     25.252  56081400\n",
       "1 2012-01-06     25.644  99455500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge semantics using default inner join\n",
    "pd.merge(msftAR0_5, msftVR2_4)\n",
    "\n",
    "# renc: merge looks like doing intersect ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date  Adj Close     Volume\n",
       "0 2012-01-03     24.422        NaN\n",
       "1 2012-01-04     24.997        NaN\n",
       "2 2012-01-05     25.252  5.608e+07\n",
       "3 2012-01-06     25.644  9.946e+07\n",
       "4 2012-01-09     25.307        NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same joing but using\n",
    "pd.merge(msftAR0_5, msftVR2_4, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Adj Close       Date     Volume\n",
       "0     24.422 2012-01-03        NaN\n",
       "1     24.997 2012-01-04        NaN\n",
       "2     25.252 2012-01-05        NaN\n",
       "3     25.644 2012-01-06        NaN\n",
       "4     25.307 2012-01-09        NaN\n",
       "2        NaN 2012-01-05  5.608e+07\n",
       "3        NaN 2012-01-06  9.946e+07"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([msftAR0_5, msftVR2_4])\n",
    "\n",
    "# renc: concat vs. merge   \n",
    "# renc: concat: first find a common column from two dataframe, and add data long that common column.\n",
    "# renc: merge: first find a common column from two dataframe, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to insert Symbol column before combining\n",
    "msft.insert(0, 'Symbol', 'MSFT')\n",
    "aapl.insert(0, 'Symbol', 'AAPL')\n",
    "\n",
    "# concatenate the MSFT and AAPL data\n",
    "# index will consist of the Date column, which we will sort\n",
    "combined = pd.concat([msft, aapl]).sort_index()\n",
    "\n",
    "# this pushes the index into a column and resets to a \n",
    "# default integer index\n",
    "s4p = combined.reset_index();\n",
    "s4p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot Date into the Index, make the columns match the\n",
    "# unique values in the Symbol column, and the values \n",
    "# will be the AdjClose values\n",
    "closes = s4p.pivot(index='Date', columns='Symbol', \n",
    "                   values='Adj Close')\n",
    "closes[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Unstacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the first level of columns into the index\n",
    "# essentially, moves AAPL and MSFT into the index\n",
    "# leaving a single colum which is the AdjClose values\n",
    "stackedCloses = closes.stack()\n",
    "stackedCloses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .ix we can retrieve close values by\n",
    "# specifying both the date and ticker\n",
    "stackedCloses.ix['2012-01-03', 'AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup on just the date, which will give us two values\n",
    "# one each for AAPL and MSFT.  \n",
    "stackedCloses.ix['2012-01-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this looks up all values for the MSFT symbol\n",
    "stackedCloses.ix[:, 'MSFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivots the last level of the index back into a column\n",
    "unstackedCloses = stackedCloses.unstack()\n",
    "unstackedCloses[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt making id_vars of Date and Symbol, making the \n",
    "# column names the variable and the for each the value\n",
    "melted = pd.melt(s4p, id_vars=['Date', 'Symbol'])\n",
    "melted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the values for the data for MSFT on 2012-01-03\n",
    "melted[(melted.Date=='2012-01-03') & (melted.Symbol=='MSFT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a DataFrame to demonstrate splitting\n",
    "# extract from combined the Symbol and AdjClose, and reset the index\n",
    "s4g = combined[['Symbol', 'Adj Close']].reset_index()\n",
    "# now, add two columns, year and month, using the year and month\n",
    "# portions of the data as integers\n",
    "s4g.insert(1, 'Year', pd.DatetimeIndex(s4g['Date']).year)\n",
    "s4g.insert(2, 'Month',pd.DatetimeIndex(s4g['Date']).month)\n",
    "s4g[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by the Symbol column\n",
    "s4g.groupby('Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group again, but save the result this time\n",
    "grouped = s4g.groupby('Symbol')\n",
    "# the groupby object has a property groups, which shows how\n",
    "# all rows will in mapped into the groups.   \n",
    "# the type of this object is a python dict\n",
    "type(grouped.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the mappings of rows to groups\n",
    "grouped.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these report the number of groups that resulted from\n",
    "# the grouping\n",
    "len(grouped), grouped.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will print the contents of a group\n",
    "def print_groups (groupobject):\n",
    "    for name, group in groupobject:\n",
    "        print name\n",
    "        print group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine our resulting groups\n",
    "print_groups(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .size will tell us the count of items in each group\n",
    "grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a specific group can be retrieved using .get_group()\n",
    "# which returns a DataFrame representing the specified group\n",
    "grouped.get_group('MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by three different fields and print the result\n",
    "mcg = s4g.groupby(['Symbol', 'Year', 'Month'])\n",
    "print_groups(mcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index of the data to be the following three fields\n",
    "# we are creating a multiindex\n",
    "mi = s4g.set_index(['Symbol', 'Year', 'Month'])\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can group based upon values in the actual index\n",
    "# the following groups by level 0 of the index (Month)\n",
    "mig_l1 = mi.groupby(level=0)\n",
    "print_groups(mig_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by three levels in the index using their names\n",
    "mig_l12 = mi.groupby(level=['Symbol', 'Year', 'Month'])\n",
    "print_groups(mig_l12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will apply the mean function to each group\n",
    "mig_l12.agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of groupby that also ignores the index\n",
    "# resulting in a default integer index\n",
    "# this also has the mean function applied\n",
    "s4g.groupby(['Symbol', 'Year', 'Month'], \n",
    "            as_index=False).agg(np.mean)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply multiple functions to each group in one call\n",
    "mig_l12.agg([np.mean, np.std])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
