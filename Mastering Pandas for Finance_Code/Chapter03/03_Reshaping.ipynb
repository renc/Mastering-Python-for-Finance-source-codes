{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping, Reorganizing and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and NumPy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# date and time functions\n",
    "import datetime\n",
    "\n",
    "# bring in matplotlib and draw inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set some Pandas options\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading historical stock data from the web or from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.io.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7304698d1723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# for the DataReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mweb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# start end end dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2012\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.io.data'"
     ]
    }
   ],
   "source": [
    "# for the DataReader\n",
    "import pandas.io.data as web\n",
    "\n",
    "# start end end dates\n",
    "start = datetime.datetime(2012, 1, 1)\n",
    "end = datetime.datetime(2012, 12, 30)\n",
    "\n",
    "# load the data\n",
    "msft = web.DataReader(\"MSFT\", 'yahoo', start, end)\n",
    "aapl = web.DataReader(\"AAPL\", 'yahoo', start, end)\n",
    "\n",
    "# these save the data to file - optional for the examples\n",
    "#msft.to_csv(\"msft.csv\")\n",
    "#aapl.to_csv(\"aapl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Microsoft and Apple data from file\n",
    "msft = pd.read_csv(\"msft.csv\", index_col=0, parse_dates=True)\n",
    "aapl = pd.read_csv(\"aapl.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing the data for the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open   High    Low  Close    Volume  Adj Close\n",
       "Date                                                       \n",
       "2012-01-03  26.55  26.96  26.39  26.77  64731500     24.422\n",
       "2012-01-04  26.82  27.47  26.78  27.40  80516100     24.997\n",
       "2012-01-05  27.38  27.73  27.29  27.68  56081400     25.252"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganizing and reshaping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating data in Multiple DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MSFT adjusted close data for Jan and Feb 2012\n",
    "msftA01 = msft['2012-01'][['Adj Close']]\n",
    "msftA02 = msft['2012-02'][['Adj Close']]\n",
    "msftA01[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msftA02[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the first three rows of each of msftA01 and msftA02\n",
    "pd.concat([msftA01.head(3), msftA02.head(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the Jan 2012 AAPL values.  \n",
    "aaplA01 = aapl['2012-01'][['Adj Close']]\n",
    "# now concat the AAPL and MSFT Jan 2012 data\n",
    "# there will be duplicate index labels\n",
    "withDups = pd.concat([msftA01[:3], aaplA01[:3]])\n",
    "withDups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the two records for data of 2012-01-03\n",
    "withDups.ix['2012-01-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate concat with a specification of the \n",
    "# stock tickets being part of the index\n",
    "# this help disambiguate the duplicate dates using\n",
    "# a hierarchal index\n",
    "closes = pd.concat([msftA01[:3], aaplA01[:3]], \n",
    "                    keys=['MSFT', 'AAPL'])\n",
    "closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract just MSFT values using .ix\n",
    "closes.ix['MSFT'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate concatenation using two DataFrame's\n",
    "# that each have two columns.  pandas will align the\n",
    "# data in columns by the column names (labels)\n",
    "msftAV = msft[['Adj Close', 'Volume']]\n",
    "aaplAV = aapl[['Adj Close', 'Volume']]\n",
    "pd.concat([msftAV, aaplAV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate concatenation with DataFrame objects\n",
    "# that do not have the same set of columns\n",
    "# this demonstrates pandas filling in NaN values\n",
    "aaplA = aapl[['Adj Close']]\n",
    "pd.concat([msftAV, aaplA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform an inner join on the DataFrame's\n",
    "# since aaplA does not have a Volume column, pandas\n",
    "# will not include that column in the result\n",
    "pd.concat([msftAV, aaplA], join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat along the rows, causing duplicate columns to\n",
    "# be created in the result\n",
    "msftA = msft[['Adj Close']]\n",
    "closes = pd.concat([msftA, aaplA], axis=1)\n",
    "closes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat along rows using two DataFrame objects with\n",
    "# different number of rows. This demonstrates how\n",
    "# NaN values will be filled in those rows for AAPL\n",
    "# which only hase three rows as compared to 5 for MSFT\n",
    "pd.concat([msftAV[:5], aaplAV[:3]], axis=1,\n",
    "          keys=['MSFT', 'AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join can also be used along this axis\n",
    "# this will not include rows with index labels that do\n",
    "# not exist in both DataFrame objects\n",
    "pd.concat([msftA[:5], aaplA[:3]], axis=1,\n",
    "          join='inner', keys=['MSFT', 'AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore indexes and just concatenate the data and\n",
    "# have the result have a default integer index\n",
    "pd.concat([msftA[:3], aaplA[:3]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will merge these two DataFrame objects, \n",
    "# so lets peek at the data to remind ourselves\n",
    "# of what they contain\n",
    "msftAR = msftA.reset_index()\n",
    "msftVR = msft[['Volume']].reset_index()\n",
    "msftAR[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msftVR[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two.  pandas finds the columns in common,\n",
    "# in this case Date, and merges on that column and adds\n",
    "# a column for all the other columns in both DataFrame's\n",
    "msftCVR = pd.merge(msftAR, msftVR)\n",
    "msftCVR[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will demonstrate join semantics using this DataFrame\n",
    "msftAR0_5 = msftAR[0:5]\n",
    "msftAR0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and also this one\n",
    "msftVR2_4 = msftVR[2:4]\n",
    "msftVR2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge semantics using default inner join\n",
    "pd.merge(msftAR0_5, msftVR2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same joing but using\n",
    "pd.merge(msftAR0_5, msftVR2_4, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to insert Symbol column before combining\n",
    "msft.insert(0, 'Symbol', 'MSFT')\n",
    "aapl.insert(0, 'Symbol', 'AAPL')\n",
    "\n",
    "# concatenate the MSFT and AAPL data\n",
    "# index will consist of the Date column, which we will sort\n",
    "combined = pd.concat([msft, aapl]).sort_index()\n",
    "\n",
    "# this pushes the index into a column and resets to a \n",
    "# default integer index\n",
    "s4p = combined.reset_index();\n",
    "s4p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot Date into the Index, make the columns match the\n",
    "# unique values in the Symbol column, and the values \n",
    "# will be the AdjClose values\n",
    "closes = s4p.pivot(index='Date', columns='Symbol', \n",
    "                   values='Adj Close')\n",
    "closes[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Unstacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the first level of columns into the index\n",
    "# essentially, moves AAPL and MSFT into the index\n",
    "# leaving a single colum which is the AdjClose values\n",
    "stackedCloses = closes.stack()\n",
    "stackedCloses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .ix we can retrieve close values by\n",
    "# specifying both the date and ticker\n",
    "stackedCloses.ix['2012-01-03', 'AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup on just the date, which will give us two values\n",
    "# one each for AAPL and MSFT.  \n",
    "stackedCloses.ix['2012-01-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this looks up all values for the MSFT symbol\n",
    "stackedCloses.ix[:, 'MSFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivots the last level of the index back into a column\n",
    "unstackedCloses = stackedCloses.unstack()\n",
    "unstackedCloses[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt making id_vars of Date and Symbol, making the \n",
    "# column names the variable and the for each the value\n",
    "melted = pd.melt(s4p, id_vars=['Date', 'Symbol'])\n",
    "melted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the values for the data for MSFT on 2012-01-03\n",
    "melted[(melted.Date=='2012-01-03') & (melted.Symbol=='MSFT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a DataFrame to demonstrate splitting\n",
    "# extract from combined the Symbol and AdjClose, and reset the index\n",
    "s4g = combined[['Symbol', 'Adj Close']].reset_index()\n",
    "# now, add two columns, year and month, using the year and month\n",
    "# portions of the data as integers\n",
    "s4g.insert(1, 'Year', pd.DatetimeIndex(s4g['Date']).year)\n",
    "s4g.insert(2, 'Month',pd.DatetimeIndex(s4g['Date']).month)\n",
    "s4g[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by the Symbol column\n",
    "s4g.groupby('Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group again, but save the result this time\n",
    "grouped = s4g.groupby('Symbol')\n",
    "# the groupby object has a property groups, which shows how\n",
    "# all rows will in mapped into the groups.   \n",
    "# the type of this object is a python dict\n",
    "type(grouped.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the mappings of rows to groups\n",
    "grouped.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these report the number of groups that resulted from\n",
    "# the grouping\n",
    "len(grouped), grouped.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will print the contents of a group\n",
    "def print_groups (groupobject):\n",
    "    for name, group in groupobject:\n",
    "        print name\n",
    "        print group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine our resulting groups\n",
    "print_groups(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .size will tell us the count of items in each group\n",
    "grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a specific group can be retrieved using .get_group()\n",
    "# which returns a DataFrame representing the specified group\n",
    "grouped.get_group('MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by three different fields and print the result\n",
    "mcg = s4g.groupby(['Symbol', 'Year', 'Month'])\n",
    "print_groups(mcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index of the data to be the following three fields\n",
    "# we are creating a multiindex\n",
    "mi = s4g.set_index(['Symbol', 'Year', 'Month'])\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can group based upon values in the actual index\n",
    "# the following groups by level 0 of the index (Month)\n",
    "mig_l1 = mi.groupby(level=0)\n",
    "print_groups(mig_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by three levels in the index using their names\n",
    "mig_l12 = mi.groupby(level=['Symbol', 'Year', 'Month'])\n",
    "print_groups(mig_l12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will apply the mean function to each group\n",
    "mig_l12.agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of groupby that also ignores the index\n",
    "# resulting in a default integer index\n",
    "# this also has the mean function applied\n",
    "s4g.groupby(['Symbol', 'Year', 'Month'], \n",
    "            as_index=False).agg(np.mean)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply multiple functions to each group in one call\n",
    "mig_l12.agg([np.mean, np.std])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
